#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Ø£Ø¯ÙˆØ§Øª ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§Ø³ØªØ¨ÙŠØ§Ù† ÙˆÙƒØ´Ù Ø§Ù„ØºØ´ - Ù†Ø³Ø®Ø© Google Colab
ÙŠÙ†Ø´Ø¦ Ù…Ù„Ù Excel Ù…ØªÙ‚Ø¯Ù… Ù…Ø¹ Ù…Ø¹Ø§Ø¯Ù„Ø§Øª ÙˆØªØ­Ù„ÙŠÙ„Ø§Øª ØªÙ„Ù‚Ø§Ø¦ÙŠØ©
"""

import pandas as pd
import numpy as np
from openpyxl import Workbook, load_workbook
from openpyxl.styles import PatternFill, Font, Alignment
import os

# Check if running in Colab
try:
    from google.colab import files
    IN_COLAB = True
    print("âœ… ØªÙ… Ø§ÙƒØªØ´Ø§Ù Ø¨ÙŠØ¦Ø© Google Colab")
except ImportError:
    IN_COLAB = False
    print("â„¹ï¸  Ù„ÙŠØ³ ÙÙŠ Google Colab")


def upload_files_colab():
    """
    Ø±ÙØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª ÙÙŠ Google Colab
    """
    if not IN_COLAB:
        print("âŒ Ù‡Ø°Ù‡ Ø§Ù„ÙˆØ¸ÙŠÙØ© ØªØ¹Ù…Ù„ ÙÙ‚Ø· ÙÙŠ Google Colab")
        return None, None
    
    print("\n" + "="*80)
    print("ğŸ“‚ Ø±ÙØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª ÙÙŠ Google Colab")
    print("="*80)
    
    # Upload real data
    print("\n1ï¸âƒ£ Ø§Ø±ÙØ¹ Ù…Ù„Ù Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠØ©:")
    print("   Ø§Ù†Ù‚Ø± Ø¹Ù„Ù‰ 'Choose Files' ÙˆØ§Ø®ØªØ± Ù…Ù„Ù CSV Ø£Ùˆ Excel")
    uploaded_real = files.upload()
    
    if not uploaded_real:
        print("âŒ Ù„Ù… ÙŠØªÙ… Ø±ÙØ¹ Ù…Ù„Ù!")
        return None, None
    
    real_path = list(uploaded_real.keys())[0]
    print(f"   âœ… ØªÙ… Ø±ÙØ¹: {real_path}")
    
    # Ask about fake data
    print("\n2ï¸âƒ£ Ù‡Ù„ ØªØ±ÙŠØ¯ Ø±ÙØ¹ Ù…Ù„Ù Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø²ÙŠÙØ©ØŸ")
    print("   Ø§ÙƒØªØ¨ 'yes' Ù„Ø±ÙØ¹ Ù…Ù„Ù Ù…Ø²ÙŠÙØŒ Ø£Ùˆ Ø§Ø¶ØºØ· Enter Ù„Ù„ØªØ®Ø·ÙŠ")
    response = input("   ğŸ‘‰ ").strip().lower()
    
    fake_path = None
    if response in ['yes', 'y', 'Ù†Ø¹Ù…']:
        print("\n   Ø§Ø±ÙØ¹ Ù…Ù„Ù Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø²ÙŠÙØ©:")
        uploaded_fake = files.upload()
        if uploaded_fake:
            fake_path = list(uploaded_fake.keys())[0]
            print(f"   âœ… ØªÙ… Ø±ÙØ¹: {fake_path}")
        else:
            print("   â­ï¸  ØªÙ… Ø§Ù„ØªØ®Ø·ÙŠ")
    else:
        print("   â­ï¸  ØªÙ… Ø§Ù„ØªØ®Ø·ÙŠ")
    
    return real_path, fake_path


def read_data_file(file_path):
    """
    Ù‚Ø±Ø§Ø¡Ø© Ù…Ù„Ù Ø¨ÙŠØ§Ù†Ø§Øª (CSV Ø£Ùˆ Excel)
    """
    try:
        file_ext = os.path.splitext(file_path)[1].lower()
        
        if file_ext == '.csv':
            # Try multiple encodings
            for encoding in ['utf-8-sig', 'utf-8', 'cp1256', 'windows-1256', 'latin1']:
                try:
                    df = pd.read_csv(file_path, encoding=encoding)
                    print(f"      âœ“ {len(df)} ØµÙ (ØªØ±Ù…ÙŠØ²: {encoding})")
                    return df
                except:
                    continue
            raise ValueError("ÙØ´Ù„ Ù‚Ø±Ø§Ø¡Ø© CSV Ø¨Ø¬Ù…ÙŠØ¹ Ø§Ù„ØªØ±Ù…ÙŠØ²Ø§Øª")
        
        elif file_ext in ['.xlsx', '.xls', '.xlsm']:
            df = pd.read_excel(file_path)
            print(f"      âœ“ {len(df)} ØµÙ")
            return df
        
        else:
            raise ValueError(f"Ù†ÙˆØ¹ Ù…Ù„Ù ØºÙŠØ± Ù…Ø¯Ø¹ÙˆÙ…: {file_ext}")
    
    except Exception as e:
        print(f"      âœ— Ø®Ø·Ø£: {e}")
        return None


def analyze_data_quality(df):
    """
    ØªØ­Ù„ÙŠÙ„ Ø¬ÙˆØ¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    """
    likert_map = {
        'Ù…ÙˆØ§ÙÙ‚ Ø¨Ø´Ø¯Ø©': 5, 'Ù…ÙˆØ§ÙÙ‚': 4, 'Ù…Ø­Ø§ÙŠØ¯': 3,
        'ØºÙŠØ± Ù…ÙˆØ§ÙÙ‚': 2, 'ØºÙŠØ± Ù…ÙˆØ§ÙÙ‚ Ø¨Ø´Ø¯Ø©': 1
    }
    
    results = []
    
    for idx, row in df.iterrows():
        result = {
            'Ø±Ù‚Ù… Ø§Ù„Ø±Ø¯': idx + 1,
            'Ø§Ù„Ù…ØµØ¯Ø±': row.get('Ù…ØµØ¯Ø± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')
        }
        
        try:
            # Find attention check columns
            q4_cols = [col for col in df.columns if 'Ù…Ø­Ø§ÙŠØ¯' in col and ('4' in col or 'Ø§Ù„Ø±Ø§Ø¨Ø¹' in col)]
            q7_cols = [col for col in df.columns if 'Ù…ÙˆØ§ÙÙ‚ Ø¨Ø´Ø¯Ø©' in col and ('7' in col or 'Ø§Ù„Ø³Ø§Ø¨Ø¹' in col)]
            
            # Check Q4
            if q4_cols:
                result['Ù†Ø¬Ø­ ÙÙŠ Ø§Ù„Ø³Ø¤Ø§Ù„ 4'] = 'Ù†Ø¹Ù…' if row[q4_cols[0]] == 'Ù…Ø­Ø§ÙŠØ¯' else 'Ù„Ø§'
            else:
                result['Ù†Ø¬Ø­ ÙÙŠ Ø§Ù„Ø³Ø¤Ø§Ù„ 4'] = 'Øº/Ù…'
            
            # Check Q7
            if q7_cols:
                result['Ù†Ø¬Ø­ ÙÙŠ Ø§Ù„Ø³Ø¤Ø§Ù„ 7'] = 'Ù†Ø¹Ù…' if row[q7_cols[0]] == 'Ù…ÙˆØ§ÙÙ‚ Ø¨Ø´Ø¯Ø©' else 'Ù„Ø§'
            else:
                result['Ù†Ø¬Ø­ ÙÙŠ Ø§Ù„Ø³Ø¤Ø§Ù„ 7'] = 'Øº/Ù…'
            
            # Find contradiction columns
            frustration_cols = [col for col in df.columns if 'Ø¥Ø­Ø¨Ø§Ø·' in col]
            happiness_cols = [col for col in df.columns if 'Ø³Ø¹Ø§Ø¯Ø©' in col]
            waste_cols = [col for col in df.columns if 'Ù‡Ø¯Ø±' in col or 'ØªÙ‡Ø¯Ø±' in col]
            control_cols = [col for col in df.columns if 'ØªØ­ÙƒÙ…' in col]
            
            # Contradiction 1
            if frustration_cols and happiness_cols:
                q6_val = likert_map.get(row[frustration_cols[0]], 0)
                q10_val = likert_map.get(row[happiness_cols[0]], 0)
                result['ØªÙ†Ø§Ù‚Ø¶ (Ø¥Ø­Ø¨Ø§Ø·+Ø³Ø¹Ø§Ø¯Ø©)'] = 'Ù†Ø¹Ù…' if (q6_val >= 4 and q10_val >= 4) else 'Ù„Ø§'
            else:
                result['ØªÙ†Ø§Ù‚Ø¶ (Ø¥Ø­Ø¨Ø§Ø·+Ø³Ø¹Ø§Ø¯Ø©)'] = 'Øº/Ù…'
            
            # Contradiction 2
            if waste_cols and control_cols:
                q8_val = likert_map.get(row[waste_cols[0]], 0)
                q9_val = likert_map.get(row[control_cols[0]], 0)
                result['ØªÙ†Ø§Ù‚Ø¶ (ÙˆÙ‚Øª+ØªØ­ÙƒÙ…)'] = 'Ù†Ø¹Ù…' if (q8_val >= 4 and q9_val >= 4) else 'Ù„Ø§'
            else:
                result['ØªÙ†Ø§Ù‚Ø¶ (ÙˆÙ‚Øª+ØªØ­ÙƒÙ…)'] = 'Øº/Ù…'
            
            # Standard deviation
            likert_cols = [col for col in df.columns if any(val in str(row[col]) for val in likert_map.keys())]
            
            if len(likert_cols) >= 5:
                responses = [likert_map.get(row[col], 0) for col in likert_cols if row[col] in likert_map]
                if len(responses) >= 5:
                    std = np.std(responses, ddof=1)
                    result['Ø§Ù„Ø§Ù†Ø­Ø±Ø§Ù Ø§Ù„Ù…Ø¹ÙŠØ§Ø±ÙŠ'] = round(std, 2)
                    result['Ø§Ù†Ø­Ø±Ø§Ù Ù…Ù†Ø®ÙØ¶'] = 'Ù†Ø¹Ù…' if std < 0.5 else 'Ù„Ø§'
                else:
                    result['Ø§Ù„Ø§Ù†Ø­Ø±Ø§Ù Ø§Ù„Ù…Ø¹ÙŠØ§Ø±ÙŠ'] = 'Øº/Ø­'
                    result['Ø§Ù†Ø­Ø±Ø§Ù Ù…Ù†Ø®ÙØ¶'] = 'Ù„Ø§'
            else:
                result['Ø§Ù„Ø§Ù†Ø­Ø±Ø§Ù Ø§Ù„Ù…Ø¹ÙŠØ§Ø±ÙŠ'] = 'Øº/Ø­'
                result['Ø§Ù†Ø­Ø±Ø§Ù Ù…Ù†Ø®ÙØ¶'] = 'Ù„Ø§'
            
            # Final assessment
            issues = sum([
                result.get('Ù†Ø¬Ø­ ÙÙŠ Ø§Ù„Ø³Ø¤Ø§Ù„ 4') == 'Ù„Ø§',
                result.get('Ù†Ø¬Ø­ ÙÙŠ Ø§Ù„Ø³Ø¤Ø§Ù„ 7') == 'Ù„Ø§',
                result.get('ØªÙ†Ø§Ù‚Ø¶ (Ø¥Ø­Ø¨Ø§Ø·+Ø³Ø¹Ø§Ø¯Ø©)') == 'Ù†Ø¹Ù…',
                result.get('ØªÙ†Ø§Ù‚Ø¶ (ÙˆÙ‚Øª+ØªØ­ÙƒÙ…)') == 'Ù†Ø¹Ù…',
                result.get('Ø§Ù†Ø­Ø±Ø§Ù Ù…Ù†Ø®ÙØ¶') == 'Ù†Ø¹Ù…'
            ])
            
            if issues == 0:
                result['Ø§Ù„ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ'] = 'âœ… Ù†Ø¸ÙŠÙ'
            elif issues <= 2:
                result['Ø§Ù„ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ'] = 'âš ï¸ Ù…Ø´Ø¨ÙˆÙ‡'
            else:
                result['Ø§Ù„ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ'] = 'âŒ Ù…Ø²ÙŠÙ'
        
        except Exception as e:
            result['Ø§Ù„ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ'] = 'âš ï¸ Ø®Ø·Ø£'
        
        results.append(result)
    
    return pd.DataFrame(results)


def create_demographics_summary(df):
    """
    Ù…Ù„Ø®Øµ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
    """
    summary = []
    
    demographics_patterns = {
        'Ø§Ù„Ø¬Ù†Ø³': ['Ø¬Ù†Ø³', 'Gender'],
        'Ø§Ù„Ø¹Ù…Ø±': ['Ø¹Ù…Ø±', 'Age'],
        'Ø§Ù„ØªØ¹Ù„ÙŠÙ…': ['ØªØ¹Ù„ÙŠÙ…', 'Ø§Ù„Ù…Ø³ØªÙˆÙ‰', 'Education'],
        'Ø§Ù„ÙˆØ¸ÙŠÙØ©': ['ÙˆØ¸ÙŠÙ', 'Ø¹Ù…Ù„', 'Job', 'Employment'],
        'Ø³Ø§Ø¹Ø§Øª Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…': ['Ø³Ø§Ø¹Ø§Øª', 'Ø§Ø³ØªØ®Ø¯Ø§Ù…', 'Usage', 'Hours']
    }
    
    for var_name, patterns in demographics_patterns.items():
        matching_cols = []
        for col in df.columns:
            if any(pattern in col for pattern in patterns):
                matching_cols.append(col)
        
        if matching_cols:
            col = matching_cols[0]
            counts = df[col].value_counts()
            for value, count in counts.items():
                summary.append({
                    'Ø§Ù„Ù…ØªØºÙŠØ±': var_name,
                    'Ø§Ù„Ù‚ÙŠÙ…Ø©': str(value),
                    'Ø§Ù„Ø¹Ø¯Ø¯': int(count),
                    'Ø§Ù„Ù†Ø³Ø¨Ø© %': round(count / len(df) * 100, 1)
                })
    
    if not summary:
        summary.append({
            'Ø§Ù„Ù…ØªØºÙŠØ±': 'ØªÙ†Ø¨ÙŠÙ‡',
            'Ø§Ù„Ù‚ÙŠÙ…Ø©': 'Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª Ø¯ÙŠÙ…ÙˆØºØ±Ø§ÙÙŠØ©',
            'Ø§Ù„Ø¹Ø¯Ø¯': 0,
            'Ø§Ù„Ù†Ø³Ø¨Ø© %': 0.0
        })
    
    return pd.DataFrame(summary)


def create_user_guide():
    """
    Ø¯Ù„ÙŠÙ„ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…
    """
    return pd.DataFrame([
        {'Ø§Ù„Ù‚Ø³Ù…': 'ğŸ“Œ Ù…Ù‚Ø¯Ù…Ø©', 'Ø§Ù„Ø´Ø±Ø­': 'Ù…Ù„Ù ØªØ­Ù„ÙŠÙ„ Ø´Ø§Ù…Ù„ Ù„Ø¬ÙˆØ¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø§Ø³ØªØ¨ÙŠØ§Ù†'},
        {'Ø§Ù„Ù‚Ø³Ù…': 'ğŸ“Š Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ÙƒØ§Ù…Ù„Ø©', 'Ø§Ù„Ø´Ø±Ø­': 'Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (Ø­Ù‚ÙŠÙ‚ÙŠØ© + Ù…Ø²ÙŠÙØ© Ø¥Ù† ÙˆØ¬Ø¯Øª)'},
        {'Ø§Ù„Ù‚Ø³Ù…': 'âœ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠØ©', 'Ø§Ù„Ø´Ø±Ø­': 'Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£ØµÙ„ÙŠØ© Ù…Ù† Ø§Ù„Ù…Ø´Ø§Ø±ÙƒÙŠÙ†'},
        {'Ø§Ù„Ù‚Ø³Ù…': 'âŒ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø²ÙŠÙØ©', 'Ø§Ù„Ø´Ø±Ø­': 'Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø­Ø§ÙƒØ§Ø© Ù„Ø£ØºØ±Ø§Ø¶ Ø§Ù„Ø¨Ø­Ø« (Ø¥Ù† ÙˆØ¬Ø¯Øª)'},
        {'Ø§Ù„Ù‚Ø³Ù…': 'ğŸ” ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¬ÙˆØ¯Ø©', 'Ø§Ù„Ø´Ø±Ø­': 'ØªÙ‚ÙŠÙŠÙ… ØªÙØµÙŠÙ„ÙŠ Ù„ÙƒÙ„ Ø±Ø¯: Ù†Ø¸ÙŠÙ / Ù…Ø´Ø¨ÙˆÙ‡ / Ù…Ø²ÙŠÙ'},
        {'Ø§Ù„Ù‚Ø³Ù…': 'ğŸ“ˆ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª', 'Ø§Ù„Ø´Ø±Ø­': 'ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¯ÙŠÙ…ÙˆØºØ±Ø§ÙÙŠØ©'},
        {'Ø§Ù„Ù‚Ø³Ù…': 'âœ“ Ù†Ø¸ÙŠÙ', 'Ø§Ù„Ø´Ø±Ø­': 'Ø±Ø¯ Ø¹Ø§Ù„ÙŠ Ø§Ù„Ø¬ÙˆØ¯Ø©ØŒ Ø§Ø¬ØªØ§Ø² Ø¬Ù…ÙŠØ¹ Ø§Ù„ÙØ­ÙˆØµØ§Øª'},
        {'Ø§Ù„Ù‚Ø³Ù…': 'âš  Ù…Ø´Ø¨ÙˆÙ‡', 'Ø§Ù„Ø´Ø±Ø­': 'Ø±Ø¯ ÙŠØ­ØªØ§Ø¬ Ù…Ø±Ø§Ø¬Ø¹Ø©ØŒ ÙØ´Ù„ ÙÙŠ 1-2 ÙØ­ÙˆØµØ§Øª'},
        {'Ø§Ù„Ù‚Ø³Ù…': 'âœ— Ù…Ø²ÙŠÙ', 'Ø§Ù„Ø´Ø±Ø­': 'Ø±Ø¯ Ù…Ù†Ø®ÙØ¶ Ø§Ù„Ø¬ÙˆØ¯Ø©ØŒ ÙØ´Ù„ ÙÙŠ 3+ ÙØ­ÙˆØµØ§Øª'},
        {'Ø§Ù„Ù‚Ø³Ù…': 'ğŸ’¡ ÙƒÙŠÙÙŠØ© Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…', 'Ø§Ù„Ø´Ø±Ø­': '1) Ø§ÙØªØ­ "ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¬ÙˆØ¯Ø©" 2) Ø±Ø§Ø¬Ø¹ Ø§Ù„Ø±Ø¯ÙˆØ¯ Ø§Ù„Ù…Ø´Ø¨ÙˆÙ‡Ø© 3) Ù‚Ø±Ø± Ø§Ù„Ø§Ø³ØªØ¨Ø¹Ø§Ø¯'},
        {'Ø§Ù„Ù‚Ø³Ù…': 'âš ï¸ Ù…Ù„Ø§Ø­Ø¸Ø©', 'Ø§Ù„Ø´Ø±Ø­': 'ÙˆØ¶Ù‘Ø­ ÙÙŠ Ø§Ù„Ø¨Ø­Ø« Ø£Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø²ÙŠÙØ© Ù„Ù„ØªÙˆØ¶ÙŠØ­ ÙÙ‚Ø·'}
    ])


def format_excel(filename):
    """
    ØªÙ†Ø³ÙŠÙ‚ Ù…Ù„Ù Excel
    """
    wb = load_workbook(filename)
    
    # Format all sheets
    for sheet_name in wb.sheetnames:
        ws = wb[sheet_name]
        
        # Header formatting
        header_fill = PatternFill(start_color="4472C4", fill_type="solid")
        header_font = Font(bold=True, color="FFFFFF", size=11)
        
        for cell in ws[1]:
            cell.fill = header_fill
            cell.font = header_font
            cell.alignment = Alignment(horizontal='center', vertical='center', wrap_text=True)
        
        # Auto-width
        for column in ws.columns:
            max_length = 0
            column_letter = column[0].column_letter
            for cell in column:
                try:
                    if len(str(cell.value)) > max_length:
                        max_length = len(str(cell.value))
                except:
                    pass
            ws.column_dimensions[column_letter].width = min(max_length + 3, 50)
        
        # Freeze first row
        ws.freeze_panes = 'A2'
    
    # Color code quality sheet
    if 'ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¬ÙˆØ¯Ø©' in wb.sheetnames:
        ws = wb['ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¬ÙˆØ¯Ø©']
        
        green = PatternFill(start_color="C6EFCE", fill_type="solid")
        yellow = PatternFill(start_color="FFEB9C", fill_type="solid")
        red = PatternFill(start_color="FFC7CE", fill_type="solid")
        
        for row in ws.iter_rows(min_row=2, max_row=ws.max_row):
            assessment = str(row[-1].value)
            
            if 'Ù†Ø¸ÙŠÙ' in assessment:
                for cell in row:
                    cell.fill = green
            elif 'Ù…Ø´Ø¨ÙˆÙ‡' in assessment:
                for cell in row:
                    cell.fill = yellow
            elif 'Ù…Ø²ÙŠÙ' in assessment:
                for cell in row:
                    cell.fill = red
    
    wb.save(filename)


def main():
    print("\n" + "="*80)
    print("ğŸ“Š ØªØ­Ù„ÙŠÙ„ Ø¬ÙˆØ¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø§Ø³ØªØ¨ÙŠØ§Ù† - Survey Quality Analyzer")
    print("="*80)
    if IN_COLAB:
        print("Ø§Ù„Ù†Ø³Ø®Ø© 4.0 - Google Colab Edition")
    else:
        print("Ø§Ù„Ù†Ø³Ø®Ø© 4.0 - Standalone Edition")
    print("="*80)
    
    # Upload or select files
    if IN_COLAB:
        real_path, fake_path = upload_files_colab()
    else:
        print("\nâš ï¸  Ù‡Ø°Ø§ Ø§Ù„ÙƒÙˆØ¯ Ù…ØµÙ…Ù… Ù„Ù€ Google Colab")
        print("Ù„Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø¹Ù„Ù‰ Ø¬Ù‡Ø§Ø²ÙƒØŒ Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù†Ø³Ø®Ø© GUI Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† Ø°Ù„Ùƒ")
        return
    
    if real_path is None:
        print("\nâŒ ØªÙ… Ø§Ù„Ø¥Ù„ØºØ§Ø¡")
        return
    
    # Read files
    print("\nğŸ“– Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„ÙØ§Øª...")
    print("="*80)
    
    print("\n  [1] Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠØ©:")
    df_real = read_data_file(real_path)
    
    if df_real is None:
        print("\nâŒ ÙØ´Ù„ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„Ù")
        return
    
    df_real['Ù…ØµØ¯Ø± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª'] = 'Ø­Ù‚ÙŠÙ‚ÙŠ'
    
    # Read fake data if provided
    df_fake = None
    if fake_path:
        print("\n  [2] Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø²ÙŠÙØ©:")
        df_fake = read_data_file(fake_path)
        if df_fake is not None:
            df_fake['Ù…ØµØ¯Ø± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª'] = 'Ù…Ø²ÙŠÙ (Ù…Ø­Ø§ÙƒØ§Ø©)'
    
    # Combine data
    if df_fake is not None:
        print("\nğŸ”€ Ø¯Ù…Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª...")
        df_combined = pd.concat([df_real, df_fake], ignore_index=True)
        print(f"   âœ“ Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹: {len(df_combined)} Ø±Ø¯")
    else:
        df_combined = df_real.copy()
    
    # Analyze
    print("\nğŸ” ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª...")
    print("="*80)
    
    print("\n  âš¡ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¬ÙˆØ¯Ø©...")
    quality_df = analyze_data_quality(df_combined)
    
    print("  âš¡ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø¯ÙŠÙ…ÙˆØºØ±Ø§ÙÙŠØ©...")
    demographics_df = create_demographics_summary(df_combined)
    
    print("  âš¡ Ø¯Ù„ÙŠÙ„ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…...")
    guide_df = create_user_guide()
    
    # Create Excel
    from datetime import datetime
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_path = f"ØªØ­Ù„ÙŠÙ„_Ø§Ù„Ø§Ø³ØªØ¨ÙŠØ§Ù†_{timestamp}.xlsx"
    
    print("\nğŸ“ Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù Excel...")
    print("="*80)
    
    try:
        with pd.ExcelWriter(output_path, engine='openpyxl') as writer:
            print("\n  ğŸ“„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ÙƒØ§Ù…Ù„Ø©...")
            df_combined.to_excel(writer, sheet_name='Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ÙƒØ§Ù…Ù„Ø©', index=False)
            
            print("  ğŸ“„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠØ©...")
            df_real.to_excel(writer, sheet_name='Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠØ©', index=False)
            
            if df_fake is not None:
                print("  ğŸ“„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø²ÙŠÙØ©...")
                df_fake.to_excel(writer, sheet_name='Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø²ÙŠÙØ©', index=False)
            
            print("  ğŸ“„ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¬ÙˆØ¯Ø©...")
            quality_df.to_excel(writer, sheet_name='ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¬ÙˆØ¯Ø©', index=False)
            
            print("  ğŸ“„ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª...")
            demographics_df.to_excel(writer, sheet_name='Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª', index=False)
            
            print("  ğŸ“„ Ø¯Ù„ÙŠÙ„ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…...")
            guide_df.to_excel(writer, sheet_name='Ø¯Ù„ÙŠÙ„ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…', index=False)
        
        print("\nğŸ¨ ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ù…Ù„Ù...")
        format_excel(output_path)
        
        print("\n" + "="*80)
        print("âœ… ØªÙ… Ø¨Ù†Ø¬Ø§Ø­!")
        print("="*80)
        print(f"\nğŸ“ Ø§Ø³Ù… Ø§Ù„Ù…Ù„Ù: {output_path}")
        
        # Summary stats
        print("\nğŸ“Š Ù…Ù„Ø®Øµ Ø§Ù„Ù†ØªØ§Ø¦Ø¬:")
        print("-"*80)
        clean = len(quality_df[quality_df['Ø§Ù„ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ'].str.contains('Ù†Ø¸ÙŠÙ', na=False)])
        suspicious = len(quality_df[quality_df['Ø§Ù„ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ'].str.contains('Ù…Ø´Ø¨ÙˆÙ‡', na=False)])
        fake = len(quality_df[quality_df['Ø§Ù„ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ'].str.contains('Ù…Ø²ÙŠÙ', na=False)])
        
        print(f"  âœ… Ù†Ø¸ÙŠÙØ©: {clean} ({clean/len(quality_df)*100:.1f}%)")
        print(f"  âš ï¸  Ù…Ø´Ø¨ÙˆÙ‡Ø©: {suspicious} ({suspicious/len(quality_df)*100:.1f}%)")
        print(f"  âŒ Ù…Ø²ÙŠÙØ©: {fake} ({fake/len(quality_df)*100:.1f}%)")
        
        # Download file in Colab
        if IN_COLAB:
            print("\nğŸ“¥ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù...")
            files.download(output_path)
            print("âœ… ØªÙ…! ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„Ù…Ù„Ù ÙÙŠ Ù…Ø¬Ù„Ø¯ Downloads")
    
    except Exception as e:
        print(f"\nâŒ Ø®Ø·Ø£: {e}")
        import traceback
        traceback.print_exc()
    
    print("\n" + "="*80)
    print("Ø§Ù†ØªÙ‡Ù‰ Ø§Ù„ØªØ­Ù„ÙŠÙ„!")
    print("="*80)


if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        print(f"\nâŒ Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹: {e}")
        import traceback
        traceback.print_exc()
